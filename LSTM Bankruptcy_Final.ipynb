{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f794c6af-b74a-43d5-85fd-d48e678aa21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, cohen_kappa_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16308d35-ac80-4d5e-8aad-38a33f07b185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e64eee4-193b-4d80-8567-b6805f294e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df1 = pd.read_csv(\"alldata36.csv\", delimiter=',', header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc1dfaa-70a1-4d03-8aa0-923f89064af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of            COMNAM   SICCD  permno          public_date   gvkey        capei  \\\n",
      "0             NaN     NaN   10001  2014-09-30 00:00:00   12994    22.123579   \n",
      "1             NaN     NaN   10001  2014-10-31 00:00:00   12994    21.261865   \n",
      "2             NaN     NaN   10001  2014-11-30 00:00:00   12994    21.337626   \n",
      "3             NaN     NaN   10001  2014-12-31 00:00:00   12994    20.447013   \n",
      "4             NaN     NaN   10001  2015-01-31 00:00:00   12994    18.090596   \n",
      "...           ...     ...     ...                  ...     ...          ...   \n",
      "575887  TESLA INC  9999.0   93436  2021-08-31 00:00:00  184996 -1158.081248   \n",
      "575888  TESLA INC  9999.0   93436  2021-09-30 00:00:00  184996 -1223.387579   \n",
      "575889  TESLA INC  9999.0   93436  2021-10-31 00:00:00  184996 -1757.896419   \n",
      "575890  TESLA INC  9999.0   93436  2021-11-30 00:00:00  184996 -2741.708578   \n",
      "575891  TESLA INC  9999.0   93436  2021-12-31 00:00:00  184996 -2604.760993   \n",
      "\n",
      "        peg_1yrforward        bm  peg_ltgforward         evm  ...  \\\n",
      "0                  NaN  0.994794             NaN   10.651209  ...   \n",
      "1                  NaN  0.994794             NaN   10.651209  ...   \n",
      "2                  NaN  0.851568             NaN   11.665765  ...   \n",
      "3                  NaN  0.851568             NaN   11.665765  ...   \n",
      "4                  NaN  0.851568             NaN   11.665765  ...   \n",
      "...                ...       ...             ...         ...  ...   \n",
      "575887        2.832805  0.037180        7.403159  108.000973  ...   \n",
      "575888        2.956623  0.037180       11.484101  108.000973  ...   \n",
      "575889        3.962398  0.037180       15.822425  108.000973  ...   \n",
      "575890        2.179457  0.034798        5.087261   98.669229  ...   \n",
      "575891        2.011956  0.034798        4.696282   98.669229  ...   \n",
      "\n",
      "        sale_invcap  sale_nwc   accrual   rd_sale  adv_sale  staff_sale  \\\n",
      "0          0.941472       NaN -0.021361  0.000000       0.0         0.0   \n",
      "1          0.941472       NaN -0.021361  0.000000       0.0         0.0   \n",
      "2          0.941355       NaN -0.038882  0.000000       0.0         0.0   \n",
      "3          0.941355       NaN -0.038882  0.000000       0.0         0.0   \n",
      "4          0.941355       NaN -0.038882  0.000000       0.0         0.0   \n",
      "...             ...       ...       ...       ...       ...         ...   \n",
      "575887     1.247926  4.286833 -0.143450  0.050881       0.0         0.0   \n",
      "575888     1.247926  4.286833 -0.143450  0.050881       0.0         0.0   \n",
      "575889     1.247926  4.286833 -0.143450  0.050881       0.0         0.0   \n",
      "575890     1.324288  4.987809 -0.122502  0.050696       0.0         0.0   \n",
      "575891     1.324288  4.987809 -0.122502  0.050696       0.0         0.0   \n",
      "\n",
      "        DLSTCD        date  Bankruptcy  Bankrupt  \n",
      "0          NaN  2014-09-30       False     False  \n",
      "1          NaN  2014-10-31       False     False  \n",
      "2          NaN  2014-11-30       False     False  \n",
      "3          NaN  2014-12-31       False     False  \n",
      "4          NaN  2015-01-31       False     False  \n",
      "...        ...         ...         ...       ...  \n",
      "575887     NaN  2021-08-31       False     False  \n",
      "575888     NaN  2021-09-30       False     False  \n",
      "575889     NaN  2021-10-31       False     False  \n",
      "575890     NaN  2021-11-30       False     False  \n",
      "575891     NaN  2021-12-31       False     False  \n",
      "\n",
      "[575892 rows x 80 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df1.head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a46513-6756-47d9-be73-052f1ee54ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Number of bankrupt companies: 2154\n",
      "Initial Number of non-bankrupt companies: 13843\n",
      "Filtered Number of bankrupt companies: 2154\n",
      "Filtered Number of non-bankrupt companies: 13843\n"
     ]
    }
   ],
   "source": [
    "# Convert 'public_date' to datetime and sort data\n",
    "df1['public_date'] = pd.to_datetime(df1['public_date'])\n",
    "df1 = df1.sort_values(by=['permno', 'public_date'])\n",
    "\n",
    "# Get unique company counts before filtering\n",
    "initial_bankrupt_count = df1[df1['Bankrupt']].drop_duplicates('permno').shape[0]\n",
    "initial_non_bankrupt_count = df1[~df1['Bankrupt']].drop_duplicates('permno').shape[0]\n",
    "\n",
    "# Specify the periods, adjusted for zero-based index\n",
    "periods = [x - 1 for x in [3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36]]\n",
    "\n",
    "# Filter rows for each 'permno' based on the specified periods\n",
    "filtered_df1 = df1.groupby('permno').nth(periods).reset_index()\n",
    "\n",
    "# Count unique bankrupt and non-bankrupt companies post-filtering\n",
    "filtered_bankrupt_count = filtered_df1[filtered_df1['Bankrupt']].drop_duplicates('permno').shape[0]\n",
    "filtered_non_bankrupt_count = filtered_df1[~filtered_df1['Bankrupt']].drop_duplicates('permno').shape[0]\n",
    "\n",
    "# Print the initial and post-filtering counts\n",
    "print(f\"Initial Number of bankrupt companies: {initial_bankrupt_count}\")\n",
    "print(f\"Initial Number of non-bankrupt companies: {initial_non_bankrupt_count}\")\n",
    "print(f\"Filtered Number of bankrupt companies: {filtered_bankrupt_count}\")\n",
    "print(f\"Filtered Number of non-bankrupt companies: {filtered_non_bankrupt_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0f94554-8c07-4a91-89c1-76808a233625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratios\n",
    "ratios = ['capital_ratio', 'equity_invcap', 'debt_invcap', 'totdebt_invcap', 'at_turn',\n",
    "         'inv_turn', 'pay_turn', 'rect_turn', 'sale_equity', 'sale_invcap', 'sale_nwc',\n",
    "         'invt_act', 'rect_act', 'fcf_ocf', 'ocf_lct', 'cash_debt', 'cash_lt', 'cfm',\n",
    "         'short_debt', 'profit_lct', 'curr_debt', 'debt_ebitda', 'dltt_be', 'int_debt',\n",
    "         'int_totdebt', 'lt_debt', 'lt_ppent', 'cash_conversion', 'cash_ratio', 'curr_ratio',\n",
    "         'quick_ratio', 'accrual', 'rd_sale', 'adv_sale', 'staff_sale', 'efftax', 'gprof',\n",
    "         'aftret_eq', 'aftret_equity', 'aftret_invcapx', 'gpm', 'npm', 'opmad', 'opmbd',\n",
    "         'pretret_earnat', 'pretret_noa', 'ptpm', 'roa', 'roce', 'roe', 'de_ratio',\n",
    "         'debt_assets', 'debt_at', 'debt_capital', 'intcov', 'intcov_ratio', 'dpr', 'bm',\n",
    "         'capei', 'divyield', 'evm', 'pcf', 'pe_exi', 'pe_inc', 'pe_op_basic', 'pe_op_dil',\n",
    "         'ps', 'ptb', 'peg_1yrforward', 'peg_ltgforward', 'peg_trailing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75378dc4-4d1e-43d9-b759-bcb42b4a4b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for LSTM\n",
    "X, y = [], []\n",
    "grouped = filtered_df1.groupby('permno')\n",
    "sequence_length = 12\n",
    "\n",
    "for _, group in grouped:\n",
    "    group = group.sort_values(by='date')\n",
    "    if len(group) >= sequence_length:\n",
    "        X.append(group[ratios].tail(sequence_length).values)\n",
    "        y.append(group['Bankruptcy'].iloc[-1])\n",
    "\n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0b2ae83-4b5c-46af-a10d-beb3c305ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset based on the date ranges\n",
    "train_mask = (filtered_df1['public_date'] >= '1970-01-01') & (filtered_df1['public_date'] <= '2010-12-31')\n",
    "test_mask = (filtered_df1['public_date'] >= '1970-01-01') & (filtered_df1['public_date'] <= '2020-12-31')\n",
    "out_sample_mask = (filtered_df1['public_date'] >= '2011-01-01') & (filtered_df1['public_date'] <= '2020-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ce17b25-dda9-4a59-baa5-71d9c9daa5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (12505, 12, 71), (12505,)\n",
      "Testing data shape: (15261, 12, 71), (15261,)\n",
      "Training bankrupt companies: 1983\n",
      "Training non-bankrupt companies: 9460\n",
      "Testing bankrupt companies: 2154\n",
      "Testing non-bankrupt companies: 13843\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([X[i] for i in range(len(X)) if train_mask.iloc[i]])\n",
    "y_train = np.array([y[i] for i in range(len(y)) if train_mask.iloc[i]])\n",
    "X_test = np.array([X[i] for i in range(len(X)) if test_mask.iloc[i]])\n",
    "y_test = np.array([y[i] for i in range(len(y)) if test_mask.iloc[i]])\n",
    "X_out = np.array([X[i] for i in range(len(X)) if out_sample_mask.iloc[i]])\n",
    "y_out = np.array([y[i] for i in range(len(y)) if out_sample_mask.iloc[i]])\n",
    "\n",
    "# Count unique bankrupt and non-bankrupt companies in the training set\n",
    "train_bankrupt_count = filtered_df1[train_mask & filtered_df1['Bankrupt']].drop_duplicates('permno').shape[0]\n",
    "train_non_bankrupt_count = filtered_df1[train_mask & ~filtered_df1['Bankrupt']].drop_duplicates('permno').shape[0]\n",
    "\n",
    "# Count unique bankrupt and non-bankrupt companies in the testing set\n",
    "test_bankrupt_count = filtered_df1[test_mask & filtered_df1['Bankrupt']].drop_duplicates('permno').shape[0]\n",
    "test_non_bankrupt_count = filtered_df1[test_mask & ~filtered_df1['Bankrupt']].drop_duplicates('permno').shape[0]\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}, {y_test.shape}\")\n",
    "print(f\"Training bankrupt companies: {train_bankrupt_count}\")\n",
    "print(f\"Training non-bankrupt companies: {train_non_bankrupt_count}\")\n",
    "print(f\"Testing bankrupt companies: {test_bankrupt_count}\")\n",
    "print(f\"Testing non-bankrupt companies: {test_non_bankrupt_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "920a90cf-40b0-4c16-9c95-3b881f3d8ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = imputer.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "X_out = imputer.transform(X_out.reshape(-1, X_out.shape[-1])).reshape(X_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a03867af-fd31-496b-8fa0-a501f6dd6ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "X_out_scaled = scaler.transform(X_out.reshape(-1, X_out.shape[-1])).reshape(X_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "409e4255-217c-44c3-b2bf-9d7cfa174923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the dataset using SMOTE\n",
    "X_train_flattened = X_train_scaled.reshape(X_train_scaled.shape[0], -1)\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = sm.fit_resample(X_train_flattened, y_train)\n",
    "X_train_resampled = X_train_resampled.reshape(-1, sequence_length, X_train_scaled.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5de070ee-8f15-4329-a873-058b5f6ecb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold and EarlyStopping setup\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "714d0c80-0075-4819-95c7-0914dae289a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store metrics\n",
    "avg_accuracy = []\n",
    "avg_recall = []\n",
    "avg_precision = []\n",
    "avg_f1 = []\n",
    "avg_roc_auc = []\n",
    "avg_kappa = []\n",
    "avg_type_ii_error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26da45e4-3dde-4ff2-9b2c-55f576c68fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Roni\\anaconda3\\envs\\lstm_env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Roni\\anaconda3\\envs\\lstm_env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 17355 samples, validate on 4339 samples\n",
      "Epoch 1/20\n",
      "17355/17355 [==============================] - 18s 1ms/sample - loss: 0.3902 - acc: 0.8328 - val_loss: 0.3383 - val_acc: 0.8594\n",
      "Epoch 2/20\n",
      "17355/17355 [==============================] - 17s 995us/sample - loss: 0.2886 - acc: 0.8836 - val_loss: 0.2778 - val_acc: 0.8878\n",
      "Epoch 3/20\n",
      "17355/17355 [==============================] - 17s 990us/sample - loss: 0.2345 - acc: 0.9121 - val_loss: 0.2456 - val_acc: 0.9115\n",
      "Epoch 4/20\n",
      "17355/17355 [==============================] - 18s 1ms/sample - loss: 0.1951 - acc: 0.9288 - val_loss: 0.2144 - val_acc: 0.9221\n",
      "Epoch 5/20\n",
      "17355/17355 [==============================] - 17s 1ms/sample - loss: 0.1586 - acc: 0.9435 - val_loss: 0.2220 - val_acc: 0.9221\n",
      "Epoch 6/20\n",
      "17355/17355 [==============================] - 17s 988us/sample - loss: 0.1456 - acc: 0.9484 - val_loss: 0.2297 - val_acc: 0.9196\n",
      "Epoch 7/20\n",
      "17355/17355 [==============================] - 17s 999us/sample - loss: 0.1301 - acc: 0.9542 - val_loss: 0.2225 - val_acc: 0.9249\n",
      "Epoch 8/20\n",
      "17355/17355 [==============================] - 17s 981us/sample - loss: 0.1162 - acc: 0.9580 - val_loss: 0.2277 - val_acc: 0.9223\n",
      "Epoch 9/20\n",
      "17355/17355 [==============================] - 17s 998us/sample - loss: 0.1039 - acc: 0.9615 - val_loss: 0.2228 - val_acc: 0.9290\n",
      "Fold 1:\n",
      "  Accuracy: 0.9221\n",
      "  Recall: 0.9394\n",
      "  Precision: 0.9075\n",
      "  F1 Score: 0.9231\n",
      "  ROC AUC: 0.9665\n",
      "  Kappa: 0.8442\n",
      "  Type II Error: 0.0606\n",
      "\n",
      "Train on 17355 samples, validate on 4339 samples\n",
      "Epoch 1/20\n",
      "17355/17355 [==============================] - 17s 1ms/sample - loss: 0.3877 - acc: 0.8338 - val_loss: 0.3116 - val_acc: 0.8721\n",
      "Epoch 2/20\n",
      "17355/17355 [==============================] - 17s 984us/sample - loss: 0.2741 - acc: 0.8937 - val_loss: 0.2442 - val_acc: 0.9044\n",
      "Epoch 3/20\n",
      "17355/17355 [==============================] - 17s 987us/sample - loss: 0.2239 - acc: 0.9181 - val_loss: 0.2219 - val_acc: 0.9205\n",
      "Epoch 4/20\n",
      "17355/17355 [==============================] - 17s 975us/sample - loss: 0.1826 - acc: 0.9333 - val_loss: 0.2199 - val_acc: 0.9256\n",
      "Epoch 5/20\n",
      "17355/17355 [==============================] - 17s 985us/sample - loss: 0.1570 - acc: 0.9423 - val_loss: 0.2046 - val_acc: 0.9260\n",
      "Epoch 6/20\n",
      "17355/17355 [==============================] - 17s 979us/sample - loss: 0.1371 - acc: 0.9518 - val_loss: 0.2220 - val_acc: 0.9221\n",
      "Epoch 7/20\n",
      "17355/17355 [==============================] - 17s 996us/sample - loss: 0.1278 - acc: 0.9552 - val_loss: 0.2596 - val_acc: 0.9154\n",
      "Epoch 8/20\n",
      "17355/17355 [==============================] - 17s 978us/sample - loss: 0.1329 - acc: 0.9510 - val_loss: 0.2186 - val_acc: 0.9209\n",
      "Epoch 9/20\n",
      "17355/17355 [==============================] - 17s 969us/sample - loss: 0.1094 - acc: 0.9597 - val_loss: 0.2106 - val_acc: 0.9316\n",
      "Epoch 10/20\n",
      "17355/17355 [==============================] - 17s 1000us/sample - loss: 0.1055 - acc: 0.9632 - val_loss: 0.1996 - val_acc: 0.9364\n",
      "Epoch 11/20\n",
      "17355/17355 [==============================] - 17s 993us/sample - loss: 0.0919 - acc: 0.9672 - val_loss: 0.1942 - val_acc: 0.9412\n",
      "Epoch 12/20\n",
      "17355/17355 [==============================] - 17s 993us/sample - loss: 0.0829 - acc: 0.9712 - val_loss: 0.2042 - val_acc: 0.9389\n",
      "Epoch 13/20\n",
      "17355/17355 [==============================] - 17s 1ms/sample - loss: 0.0723 - acc: 0.9740 - val_loss: 0.2313 - val_acc: 0.9297\n",
      "Epoch 14/20\n",
      "17355/17355 [==============================] - 17s 1ms/sample - loss: 0.0826 - acc: 0.9698 - val_loss: 0.2035 - val_acc: 0.9366\n",
      "Epoch 15/20\n",
      "17355/17355 [==============================] - 17s 982us/sample - loss: 0.0907 - acc: 0.9654 - val_loss: 0.2265 - val_acc: 0.9339\n",
      "Epoch 16/20\n",
      "17355/17355 [==============================] - 17s 998us/sample - loss: 0.0754 - acc: 0.9742 - val_loss: 0.2341 - val_acc: 0.9304\n",
      "Fold 2:\n",
      "  Accuracy: 0.9412\n",
      "  Recall: 0.9640\n",
      "  Precision: 0.9220\n",
      "  F1 Score: 0.9425\n",
      "  ROC AUC: 0.9751\n",
      "  Kappa: 0.8825\n",
      "  Type II Error: 0.0360\n",
      "\n",
      "Train on 17355 samples, validate on 4339 samples\n",
      "Epoch 1/20\n",
      "17355/17355 [==============================] - 18s 1ms/sample - loss: 0.3892 - acc: 0.8344 - val_loss: 0.3324 - val_acc: 0.8576\n",
      "Epoch 2/20\n",
      "17355/17355 [==============================] - 17s 994us/sample - loss: 0.2746 - acc: 0.8931 - val_loss: 0.2649 - val_acc: 0.8961\n",
      "Epoch 3/20\n",
      "17355/17355 [==============================] - 17s 997us/sample - loss: 0.2207 - acc: 0.9186 - val_loss: 0.2337 - val_acc: 0.9140\n",
      "Epoch 4/20\n",
      "17355/17355 [==============================] - 17s 964us/sample - loss: 0.1879 - acc: 0.9301 - val_loss: 0.2298 - val_acc: 0.9163\n",
      "Epoch 5/20\n",
      "17355/17355 [==============================] - 17s 989us/sample - loss: 0.1628 - acc: 0.9423 - val_loss: 0.2268 - val_acc: 0.9180\n",
      "Epoch 6/20\n",
      "17355/17355 [==============================] - 17s 965us/sample - loss: 0.1439 - acc: 0.9485 - val_loss: 0.2210 - val_acc: 0.9193\n",
      "Epoch 7/20\n",
      "17355/17355 [==============================] - 17s 974us/sample - loss: 0.1372 - acc: 0.9515 - val_loss: 0.2275 - val_acc: 0.9230\n",
      "Epoch 8/20\n",
      "17355/17355 [==============================] - 17s 1ms/sample - loss: 0.1228 - acc: 0.9553 - val_loss: 0.2254 - val_acc: 0.9290\n",
      "Epoch 9/20\n",
      "17355/17355 [==============================] - 17s 1ms/sample - loss: 0.1115 - acc: 0.9619 - val_loss: 0.2296 - val_acc: 0.9283\n",
      "Epoch 10/20\n",
      "17355/17355 [==============================] - 17s 995us/sample - loss: 0.1091 - acc: 0.9617 - val_loss: 0.2370 - val_acc: 0.9246\n",
      "Epoch 11/20\n",
      "17355/17355 [==============================] - 17s 1ms/sample - loss: 0.1031 - acc: 0.9629 - val_loss: 0.2497 - val_acc: 0.9292\n",
      "Fold 3:\n",
      "  Accuracy: 0.9193\n",
      "  Recall: 0.9420\n",
      "  Precision: 0.9014\n",
      "  F1 Score: 0.9213\n",
      "  ROC AUC: 0.9672\n",
      "  Kappa: 0.8387\n",
      "  Type II Error: 0.0580\n",
      "\n",
      "Train on 17355 samples, validate on 4339 samples\n",
      "Epoch 1/20\n",
      "17355/17355 [==============================] - 18s 1ms/sample - loss: 0.3908 - acc: 0.8331 - val_loss: 0.3316 - val_acc: 0.8617\n",
      "Epoch 2/20\n",
      "17355/17355 [==============================] - 17s 993us/sample - loss: 0.2853 - acc: 0.8880 - val_loss: 0.2724 - val_acc: 0.8935\n",
      "Epoch 3/20\n",
      "17355/17355 [==============================] - 17s 1ms/sample - loss: 0.2221 - acc: 0.9175 - val_loss: 0.2426 - val_acc: 0.9152\n",
      "Epoch 4/20\n",
      "17355/17355 [==============================] - 17s 997us/sample - loss: 0.1822 - acc: 0.9348 - val_loss: 0.2371 - val_acc: 0.9117\n",
      "Epoch 5/20\n",
      "17355/17355 [==============================] - 17s 1ms/sample - loss: 0.1548 - acc: 0.9456 - val_loss: 0.2315 - val_acc: 0.9230\n",
      "Epoch 6/20\n",
      "17355/17355 [==============================] - 17s 973us/sample - loss: 0.1297 - acc: 0.9539 - val_loss: 0.2273 - val_acc: 0.9230\n",
      "Epoch 7/20\n",
      "17355/17355 [==============================] - 17s 995us/sample - loss: 0.1239 - acc: 0.9556 - val_loss: 0.2315 - val_acc: 0.9249\n",
      "Epoch 8/20\n",
      "17355/17355 [==============================] - 17s 995us/sample - loss: 0.1061 - acc: 0.9636 - val_loss: 0.2404 - val_acc: 0.9258\n",
      "Epoch 9/20\n",
      "17355/17355 [==============================] - 17s 990us/sample - loss: 0.1007 - acc: 0.9653 - val_loss: 0.2392 - val_acc: 0.9239\n",
      "Epoch 10/20\n",
      "17355/17355 [==============================] - 17s 992us/sample - loss: 0.0920 - acc: 0.9681 - val_loss: 0.2410 - val_acc: 0.9320\n",
      "Epoch 11/20\n",
      "17355/17355 [==============================] - 18s 1ms/sample - loss: 0.0933 - acc: 0.9662 - val_loss: 0.2595 - val_acc: 0.9233\n",
      "Fold 4:\n",
      "  Accuracy: 0.9230\n",
      "  Recall: 0.9440\n",
      "  Precision: 0.9043\n",
      "  F1 Score: 0.9237\n",
      "  ROC AUC: 0.9660\n",
      "  Kappa: 0.8461\n",
      "  Type II Error: 0.0560\n",
      "\n",
      "Train on 17356 samples, validate on 4338 samples\n",
      "Epoch 1/20\n",
      "17356/17356 [==============================] - 18s 1ms/sample - loss: 0.3928 - acc: 0.8342 - val_loss: 0.3253 - val_acc: 0.8642\n",
      "Epoch 2/20\n",
      "17356/17356 [==============================] - 17s 995us/sample - loss: 0.2813 - acc: 0.8899 - val_loss: 0.2817 - val_acc: 0.8905\n",
      "Epoch 3/20\n",
      "17356/17356 [==============================] - 18s 1ms/sample - loss: 0.2231 - acc: 0.9174 - val_loss: 0.2497 - val_acc: 0.9087\n",
      "Epoch 4/20\n",
      "17356/17356 [==============================] - 17s 1ms/sample - loss: 0.1906 - acc: 0.9311 - val_loss: 0.2380 - val_acc: 0.9117\n",
      "Epoch 5/20\n",
      "17356/17356 [==============================] - 18s 1ms/sample - loss: 0.1547 - acc: 0.9471 - val_loss: 0.2223 - val_acc: 0.9232\n",
      "Epoch 6/20\n",
      "17356/17356 [==============================] - 17s 999us/sample - loss: 0.1327 - acc: 0.9534 - val_loss: 0.2528 - val_acc: 0.9112\n",
      "Epoch 7/20\n",
      "17356/17356 [==============================] - 18s 1ms/sample - loss: 0.1176 - acc: 0.9586 - val_loss: 0.2294 - val_acc: 0.9207\n",
      "Epoch 8/20\n",
      "17356/17356 [==============================] - 17s 1000us/sample - loss: 0.1098 - acc: 0.9611 - val_loss: 0.2403 - val_acc: 0.9209\n",
      "Epoch 9/20\n",
      "17356/17356 [==============================] - 17s 1ms/sample - loss: 0.1070 - acc: 0.9603 - val_loss: 0.2366 - val_acc: 0.9212\n",
      "Epoch 10/20\n",
      "17356/17356 [==============================] - 18s 1ms/sample - loss: 0.0857 - acc: 0.9713 - val_loss: 0.2497 - val_acc: 0.9272\n",
      "Fold 5:\n",
      "  Accuracy: 0.9232\n",
      "  Recall: 0.9546\n",
      "  Precision: 0.9002\n",
      "  F1 Score: 0.9266\n",
      "  ROC AUC: 0.9665\n",
      "  Kappa: 0.8463\n",
      "  Type II Error: 0.0454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start KFold training\n",
    "fold_var = 1\n",
    "for train_index, val_index in kf.split(X_train_resampled):\n",
    "    X_train_fold, X_val_fold = X_train_resampled[train_index], X_train_resampled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train_resampled[train_index], y_train_resampled[val_index]\n",
    "    \n",
    "    # Build the LSTM model\n",
    "    model = Sequential([\n",
    "        LSTM(50, input_shape=(sequence_length, len(ratios)), activation='tanh'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold),\n",
    "                        epochs=20, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "    # Predictions for this fold\n",
    "    y_pred = model.predict(X_val_fold)\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Calculate metrics for this fold\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred_binary)\n",
    "    recall = recall_score(y_val_fold, y_pred_binary)\n",
    "    precision = precision_score(y_val_fold, y_pred_binary)\n",
    "    f1 = f1_score(y_val_fold, y_pred_binary)\n",
    "    roc_auc = roc_auc_score(y_val_fold, y_pred)\n",
    "    kappa = cohen_kappa_score(y_val_fold, y_pred_binary)\n",
    "    type_ii_error = 1 - recall\n",
    "\n",
    "    print(f'Fold {fold_var}:')\n",
    "    print(f'  Accuracy: {accuracy:.4f}')\n",
    "    print(f'  Recall: {recall:.4f}')\n",
    "    print(f'  Precision: {precision:.4f}')\n",
    "    print(f'  F1 Score: {f1:.4f}')\n",
    "    print(f'  ROC AUC: {roc_auc:.4f}')\n",
    "    print(f'  Kappa: {kappa:.4f}')\n",
    "    print(f'  Type II Error: {type_ii_error:.4f}')\n",
    "    print()\n",
    "\n",
    "    # Append metrics for this fold to the lists\n",
    "    avg_accuracy.append(accuracy)\n",
    "    avg_recall.append(recall)\n",
    "    avg_precision.append(precision)\n",
    "    avg_f1.append(f1)\n",
    "    avg_roc_auc.append(roc_auc)\n",
    "    avg_kappa.append(kappa)\n",
    "    avg_type_ii_error.append(type_ii_error)\n",
    "\n",
    "    fold_var += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3f9f819-d90f-402c-91a3-f31ca363bb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics across all folds:\n",
      "  Average Accuracy: 0.9258\n",
      "  Average Recall: 0.9488\n",
      "  Average Precision: 0.9071\n",
      "  Average F1 Score: 0.9274\n",
      "  Average ROC AUC: 0.9683\n",
      "  Average Kappa: 0.8515\n",
      "  Average Type II Error: 0.0512\n"
     ]
    }
   ],
   "source": [
    "# Calculate average of all folds\n",
    "print('Average metrics across all folds:')\n",
    "print(f'  Average Accuracy: {np.mean(avg_accuracy):.4f}')\n",
    "print(f'  Average Recall: {np.mean(avg_recall):.4f}')\n",
    "print(f'  Average Precision: {np.mean(avg_precision):.4f}')\n",
    "print(f'  Average F1 Score: {np.mean(avg_f1):.4f}')\n",
    "print(f'  Average ROC AUC: {np.mean(avg_roc_auc):.4f}')\n",
    "print(f'  Average Kappa: {np.mean(avg_kappa):.4f}')\n",
    "print(f'  Average Type II Error: {np.mean(avg_type_ii_error):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2ee16a9-1c36-459e-9d44-f4276a0aa974",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('LSTM_Model_72_Q36.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a253905-96e2-41d7-b407-0bcb7d7ea3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Roni\\anaconda3\\envs\\lstm_env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Roni\\anaconda3\\envs\\lstm_env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Roni\\anaconda3\\envs\\lstm_env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Roni\\anaconda3\\envs\\lstm_env\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Roni\\anaconda3\\envs\\lstm_env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = load_model('LSTM_Model_72_Q36.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83d27e83-e81e-4b4c-a979-cc7dc3028316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the train set\n",
    "y_train_pred_probs = model.predict(X_train_scaled)\n",
    "y_train_pred = (y_train_pred_probs > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e4de574-0071-47f1-bfd8-50f9075936cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9370\n",
      "Train Precision: 0.6880\n",
      "Train Recall: 0.9602\n",
      "Train F1 Score: 0.8016\n",
      "Train ROC AUC: 0.9802\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_probs)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Train Precision: {train_precision:.4f}\")\n",
    "print(f\"Train Recall: {train_recall:.4f}\")\n",
    "print(f\"Train F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1af5e70-eda9-46d7-905b-483805e052c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10125   722]\n",
      " [   66  1592]]\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6aec7832-8cd3-40db-9b9b-8cf3a725f75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_test_pred_probs = model.predict(X_test_scaled)\n",
    "y_test_pred = (y_test_pred_probs > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d46bb48-11d4-4e36-a566-a0837ea6f806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9247\n",
      "Test Precision: 0.6578\n",
      "Test Recall: 0.9140\n",
      "Test F1 Score: 0.7650\n",
      "Test ROC AUC: 0.9685\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_pred_probs)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Test ROC AUC: {test_roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06676209-ce03-493e-9a52-456e4b2dc717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[12242   973]\n",
      " [  176  1870]]\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e0c2c95-f5f3-440d-8d4f-22bf0e29815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the Out of Sample set\n",
    "y_out_pred_probs = model.predict(X_out_scaled)\n",
    "y_out_pred = (y_out_pred_probs > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f939e45-2141-49be-84f0-a122000531df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of Sample Accuracy: 0.8690\n",
      "Out of Sample Precision: 0.5255\n",
      "Out of Sample Recall: 0.7165\n",
      "Out of Sample F1 Score: 0.6063\n",
      "Out of Sample ROC AUC: 0.9116\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "Out_accuracy = accuracy_score(y_out, y_out_pred)\n",
    "Out_precision = precision_score(y_out, y_out_pred)\n",
    "Out_recall = recall_score(y_out, y_out_pred)\n",
    "Out_f1 = f1_score(y_out, y_out_pred)\n",
    "Out_roc_auc = roc_auc_score(y_out, y_out_pred_probs)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Out of Sample Accuracy: {Out_accuracy:.4f}\")\n",
    "print(f\"Out of Sample Precision: {Out_precision:.4f}\")\n",
    "print(f\"Out of Sample Recall: {Out_recall:.4f}\")\n",
    "print(f\"Out of Sample F1 Score: {Out_f1:.4f}\")\n",
    "print(f\"Out of Sample ROC AUC: {Out_roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f2f93c0-5ab7-469f-b1bd-84b3fb75fd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2117  251]\n",
      " [ 110  278]]\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_out, y_out_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46fd8e8-69a2-42c3-855c-8ec1ac707ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
