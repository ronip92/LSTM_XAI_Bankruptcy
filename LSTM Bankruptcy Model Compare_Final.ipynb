{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f794c6af-b74a-43d5-85fd-d48e678aa21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, classification_report, roc_auc_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e64eee4-193b-4d80-8567-b6805f294e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"alldata36.csv\", delimiter=',')\n",
    "df['public_date'] = pd.to_datetime(df['public_date'])\n",
    "df = df.sort_values(by=['permno', 'public_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcef12eb-f9ce-4465-9e97-6cb15f952eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last entry for each company\n",
    "last_entry_df = df.groupby('permno').last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22a46513-6756-47d9-be73-052f1ee54ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "features = ['capital_ratio', 'equity_invcap', 'debt_invcap', 'totdebt_invcap', 'at_turn',\n",
    "            'inv_turn', 'pay_turn', 'rect_turn', 'sale_equity', 'sale_invcap', 'sale_nwc',\n",
    "            'invt_act', 'rect_act', 'fcf_ocf', 'ocf_lct', 'cash_debt', 'cash_lt', 'cfm',\n",
    "            'short_debt', 'profit_lct', 'curr_debt', 'debt_ebitda', 'dltt_be', 'int_debt',\n",
    "            'int_totdebt', 'lt_debt', 'lt_ppent', 'cash_conversion', 'cash_ratio', 'curr_ratio',\n",
    "            'quick_ratio', 'accrual', 'rd_sale', 'adv_sale', 'staff_sale', 'efftax', 'gprof',\n",
    "            'aftret_eq', 'aftret_equity', 'aftret_invcapx', 'gpm', 'npm', 'opmad', 'opmbd',\n",
    "            'pretret_earnat', 'pretret_noa', 'ptpm', 'roa', 'roce', 'roe', 'de_ratio',\n",
    "            'debt_assets', 'debt_at', 'debt_capital', 'intcov', 'intcov_ratio', 'dpr', 'bm',\n",
    "            'capei', 'divyield', 'evm', 'pcf', 'pe_exi', 'pe_inc', 'pe_op_basic', 'pe_op_dil',\n",
    "            'ps', 'ptb', 'peg_1yrforward', 'peg_ltgforward', 'peg_trailing']\n",
    "target = 'Bankruptcy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861d694e-ab34-442f-8a49-9ff2be55bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks for train, test, and out-sample datasets based on the last entry dates\n",
    "train_mask = (last_entry_df['public_date'] >= '1970-01-01') & (last_entry_df['public_date'] <= '2010-12-31')\n",
    "test_mask = (last_entry_df['public_date'] >= '1970-01-01') & (last_entry_df['public_date'] <= '2020-12-31')\n",
    "out_sample_mask = (last_entry_df['public_date'] >= '2011-01-01') & (last_entry_df['public_date'] <= '2020-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0b2ae83-4b5c-46af-a10d-beb3c305ce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the datasets\n",
    "train_df = last_entry_df[train_mask]\n",
    "test_df = last_entry_df[test_mask]\n",
    "out_sample_df = last_entry_df[out_sample_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f08dc67b-1b80-4ff0-9fb8-7135a551f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target\n",
    "X_train = train_df[features].values\n",
    "y_train = train_df[target].values\n",
    "X_test = test_df[features].values\n",
    "y_test = test_df[target].values\n",
    "X_out = out_sample_df[features].values\n",
    "y_out = out_sample_df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "920a90cf-40b0-4c16-9c95-3b881f3d8ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "X_out = imputer.transform(X_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a03867af-fd31-496b-8fa0-a501f6dd6ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_out_scaled = scaler.transform(X_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "409e4255-217c-44c3-b2bf-9d7cfa174923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the dataset using SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = sm.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc0162e3-438e-485c-a7a8-424b249c7403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build MDA model\n",
    "lda = LDA(n_components=None, solver='svd', tol=0.0001)\n",
    "lda.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cdff028-20de-40e7-9bb5-c78ab8bce4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions Training Data\n",
    "y_pred = lda.predict(X_train_scaled)\n",
    "y_pred_probs = lda.predict_proba(X_train_scaled)[:, 1]  # assuming the positive class is at index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41b4a58f-34ab-48e4-a285-bbcebcc23140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7627\n",
      "Train Precision: 0.4046\n",
      "Train Recall: 0.7474\n",
      "Train F1 Score: 0.5250\n",
      "Train ROC AUC: 0.8188\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "train_accuracy = accuracy_score(y_train, y_pred)\n",
    "train_precision = precision_score(y_train, y_pred)\n",
    "train_recall = recall_score(y_train, y_pred)\n",
    "train_f1 = f1_score(y_train, y_pred)\n",
    "train_roc_auc = roc_auc_score(y_train, y_pred_probs)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Train Precision: {train_precision:.4f}\")\n",
    "print(f\"Train Recall: {train_recall:.4f}\")\n",
    "print(f\"Train F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Train ROC AUC: {train_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a5a43db-a3ad-42cd-bc02-a5ecd39ba6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[6822 2085]\n",
      " [ 479 1417]]\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the confusion matrix Training Data \n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d2b26d6-d615-4fad-ab3b-dfa3a64a3de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions Testing Data\n",
    "y_pred = lda.predict(X_test_scaled)\n",
    "y_pred_probs = lda.predict_proba(X_test_scaled)[:, 1]  # assuming the positive class is at index 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55b3cd1f-0b0c-4ffd-8eed-79427431c902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7626\n",
      "Test Precision: 0.3904\n",
      "Test Recall: 0.7380\n",
      "Test F1 Score: 0.5106\n",
      "Test ROC AUC: 0.8153\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_precision = precision_score(y_test, y_pred)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_probs)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Test ROC AUC: {test_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1af5e70-eda9-46d7-905b-483805e052c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[8180 2477]\n",
      " [ 563 1586]]\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4657a4dc-f788-4dbb-89ef-5ac6cdb17f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions Out-of-Sample LDA\n",
    "y_pred = lda.predict(X_out_scaled)\n",
    "y_pred_probs = lda.predict_proba(X_out_scaled)[:, 1]  # assuming the positive class is at index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "631d99ba-7c2a-46c2-af74-82ee89413e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out Accuracy: 0.7624\n",
      "Out Precision: 0.3012\n",
      "Out Recall: 0.6680\n",
      "Out F1 Score: 0.4152\n",
      "Out ROC AUC: 0.7879\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "out_accuracy = accuracy_score(y_out, y_pred)\n",
    "out_precision = precision_score(y_out, y_pred)\n",
    "out_recall = recall_score(y_out, y_pred)\n",
    "out_f1 = f1_score(y_out, y_pred)\n",
    "out_roc_auc = roc_auc_score(y_out, y_pred_probs)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Out Accuracy: {out_accuracy:.4f}\")\n",
    "print(f\"Out Precision: {out_precision:.4f}\")\n",
    "print(f\"Out Recall: {out_recall:.4f}\")\n",
    "print(f\"Out F1 Score: {out_f1:.4f}\")\n",
    "print(f\"Out ROC AUC: {out_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79b737fc-5d95-4fae-a9fe-7724e38ac303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1358  392]\n",
      " [  84  169]]\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_out, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e0c2c95-f5f3-440d-8d4f-22bf0e29815f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=10000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e235b32-2281-4b4e-b405-e5d1b1c07d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the train data\n",
    "y_pred_lr = log_reg.predict(X_train_scaled)\n",
    "y_pred_probs_lr = log_reg.predict_proba(X_train_scaled)[:, 1]  # probabilities for the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d61680e0-9d8d-4e98-a691-4bef2003495f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train Accuracy: 0.7790\n",
      "Logistic Regression Train Precision: 0.4290\n",
      "Logistic Regression Train Recall: 0.7838\n",
      "Logistic Regression Train F1 Score: 0.5545\n",
      "Logistic Regression Train ROC AUC: 0.8390\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "train_accuracy_lr = accuracy_score(y_train, y_pred_lr)\n",
    "train_precision_lr = precision_score(y_train, y_pred_lr, zero_division=1)\n",
    "train_recall_lr = recall_score(y_train, y_pred_lr, zero_division=1)\n",
    "train_f1_lr = f1_score(y_train, y_pred_lr, zero_division=1)\n",
    "train_roc_auc_lr = roc_auc_score(y_train, y_pred_probs_lr)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Logistic Regression Train Accuracy: {train_accuracy_lr:.4f}\")\n",
    "print(f\"Logistic Regression Train Precision: {train_precision_lr:.4f}\")\n",
    "print(f\"Logistic Regression Train Recall: {train_recall_lr:.4f}\")\n",
    "print(f\"Logistic Regression Train F1 Score: {train_f1_lr:.4f}\")\n",
    "print(f\"Logistic Regression Train ROC AUC: {train_roc_auc_lr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80c15344-b79b-4404-9b20-f1c282a49ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[6929 1978]\n",
      " [ 410 1486]]\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_train, y_pred_lr)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bdd2dcd-20ee-423d-a380-8d2c937f4c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_lr = log_reg.predict(X_test_scaled)\n",
    "y_pred_probs_lr = log_reg.predict_proba(X_test_scaled)[:, 1]  # probabilities for the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15da8d7d-e377-43bd-a6f5-4320deafa382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.7816\n",
      "Logistic Regression Test Precision: 0.4186\n",
      "Logistic Regression Test Recall: 0.7748\n",
      "Logistic Regression Test F1 Score: 0.5435\n",
      "Logistic Regression Test ROC AUC: 0.8379\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "test_precision_lr = precision_score(y_test, y_pred_lr, zero_division=1)\n",
    "test_recall_lr = recall_score(y_test, y_pred_lr, zero_division=1)\n",
    "test_f1_lr = f1_score(y_test, y_pred_lr, zero_division=1)\n",
    "test_roc_auc_lr = roc_auc_score(y_test, y_pred_probs_lr)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Logistic Regression Test Accuracy: {test_accuracy_lr:.4f}\")\n",
    "print(f\"Logistic Regression Test Precision: {test_precision_lr:.4f}\")\n",
    "print(f\"Logistic Regression Test Recall: {test_recall_lr:.4f}\")\n",
    "print(f\"Logistic Regression Test F1 Score: {test_f1_lr:.4f}\")\n",
    "print(f\"Logistic Regression Test ROC AUC: {test_roc_auc_lr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "125aa60e-560a-4d53-8f98-65b6437c4d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[8344 2313]\n",
      " [ 484 1665]]\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_lr)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43dd92af-0f19-44d5-ad18-9f317a39b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the out-of-sample data\n",
    "y_pred_lr = log_reg.predict(X_out_scaled)\n",
    "y_pred_probs_lr = log_reg.predict_proba(X_out_scaled)[:, 1]  # probabilities for the positive class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab8a3bdd-e085-46ce-bfbd-68243f321b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression out Accuracy: 0.7958\n",
      "Logistic Regression out Precision: 0.3482\n",
      "Logistic Regression out Recall: 0.7075\n",
      "Logistic Regression out F1 Score: 0.4668\n",
      "Logistic Regression out ROC AUC: 0.8236\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "out_accuracy_lr = accuracy_score(y_out, y_pred_lr)\n",
    "out_precision_lr = precision_score(y_out, y_pred_lr, zero_division=1)\n",
    "out_recall_lr = recall_score(y_out, y_pred_lr, zero_division=1)\n",
    "out_f1_lr = f1_score(y_out, y_pred_lr, zero_division=1)\n",
    "out_roc_auc_lr = roc_auc_score(y_out, y_pred_probs_lr)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Logistic Regression out Accuracy: {out_accuracy_lr:.4f}\")\n",
    "print(f\"Logistic Regression out Precision: {out_precision_lr:.4f}\")\n",
    "print(f\"Logistic Regression out Recall: {out_recall_lr:.4f}\")\n",
    "print(f\"Logistic Regression out F1 Score: {out_f1_lr:.4f}\")\n",
    "print(f\"Logistic Regression out ROC AUC: {out_roc_auc_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc15350a-5ded-4c98-9dba-bb2ac8ddd848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1415  335]\n",
      " [  74  179]]\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_out, y_pred_lr)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16085642-da54-4ad7-8926-7216254a2388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=50, n_jobs=-1,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest model with adjusted parameters\n",
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=50,  # Reduced number of trees\n",
    "    max_depth=10,     # Limiting depth of each tree\n",
    "    n_jobs=-1,        # Use all available cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "random_forest.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89a8cec1-eb78-479a-8386-66f8434a600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the train data\n",
    "y_pred_rf = random_forest.predict(X_train_scaled)\n",
    "y_pred_probs_rf = random_forest.predict_proba(X_train_scaled)[:, 1]  # probabilities for the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36f6526c-102e-40ac-8dc5-68c347d91f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train Accuracy: 0.8822\n",
      "Random Forest Train Precision: 0.6040\n",
      "Random Forest Train Recall: 0.9541\n",
      "Random Forest Train F1 Score: 0.7397\n",
      "Random Forest Train ROC AUC: 0.9644\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "train_accuracy_rf = accuracy_score(y_train, y_pred_rf)\n",
    "train_precision_rf = precision_score(y_train, y_pred_rf, zero_division=1)\n",
    "train_recall_rf = recall_score(y_train, y_pred_rf, zero_division=1)\n",
    "train_f1_rf = f1_score(y_train, y_pred_rf, zero_division=1)\n",
    "train_roc_auc_rf = roc_auc_score(y_train, y_pred_probs_rf)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Random Forest Train Accuracy: {train_accuracy_rf:.4f}\")\n",
    "print(f\"Random Forest Train Precision: {train_precision_rf:.4f}\")\n",
    "print(f\"Random Forest Train Recall: {train_recall_rf:.4f}\")\n",
    "print(f\"Random Forest Train F1 Score: {train_f1_rf:.4f}\")\n",
    "print(f\"Random Forest Train ROC AUC: {train_roc_auc_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "994fabd1-6667-44fb-9469-d5890db3b85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[7721 1186]\n",
      " [  87 1809]]\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_train, y_pred_rf)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cbc95c4-a5fd-4bc0-88df-4a1b812b3bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_rf = random_forest.predict(X_test_scaled)\n",
    "y_pred_probs_rf = random_forest.predict_proba(X_test_scaled)[:, 1]  # probabilities for the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56ac6ffb-e704-4837-8422-a339d8a85be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Accuracy: 0.8740\n",
      "Random Forest Test Precision: 0.5763\n",
      "Random Forest Test Recall: 0.9423\n",
      "Random Forest Test F1 Score: 0.7152\n",
      "Random Forest Test ROC AUC: 0.9566\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "test_precision_rf = precision_score(y_test, y_pred_rf, zero_division=1)\n",
    "test_recall_rf = recall_score(y_test, y_pred_rf, zero_division=1)\n",
    "test_f1_rf = f1_score(y_test, y_pred_rf, zero_division=1)\n",
    "test_roc_auc_rf = roc_auc_score(y_test, y_pred_probs_rf)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Random Forest Test Accuracy: {test_accuracy_rf:.4f}\")\n",
    "print(f\"Random Forest Test Precision: {test_precision_rf:.4f}\")\n",
    "print(f\"Random Forest Test Recall: {test_recall_rf:.4f}\")\n",
    "print(f\"Random Forest Test F1 Score: {test_f1_rf:.4f}\")\n",
    "print(f\"Random Forest Test ROC AUC: {test_roc_auc_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9b066ee-ac1b-47d5-a6fc-c2fa9963f537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[9168 1489]\n",
      " [ 124 2025]]\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "265792ad-641d-4a8f-87b4-b0be16ac7dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the out-of-sample data\n",
    "y_pred_rf = random_forest.predict(X_out_scaled)\n",
    "y_pred_probs_rf = random_forest.predict_proba(X_out_scaled)[:, 1]  # probabilities for the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c79d4aa-eba2-4cee-93a6-1554180460d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest out Accuracy: 0.8303\n",
      "Random Forest out Precision: 0.4162\n",
      "Random Forest out Recall: 0.8538\n",
      "Random Forest out F1 Score: 0.5596\n",
      "Random Forest out ROC AUC: 0.9094\n"
     ]
    }
   ],
   "source": [
    "out_accuracy_rf = accuracy_score(y_out, y_pred_rf)\n",
    "out_precision_rf = precision_score(y_out, y_pred_rf, zero_division=1)\n",
    "out_recall_rf = recall_score(y_out, y_pred_rf, zero_division=1)\n",
    "out_f1_rf= f1_score(y_out, y_pred_rf, zero_division=1)\n",
    "out_roc_auc_rf = roc_auc_score(y_out, y_pred_probs_rf)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Random Forest out Accuracy: {out_accuracy_rf:.4f}\")\n",
    "print(f\"Random Forest out Precision: {out_precision_rf:.4f}\")\n",
    "print(f\"Random Forest out Recall: {out_recall_rf:.4f}\")\n",
    "print(f\"Random Forest out F1 Score: {out_f1_rf:.4f}\")\n",
    "print(f\"Random Forest out ROC AUC: {out_roc_auc_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a395cd6b-53e2-46cb-acc9-d2464a0832e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1447  303]\n",
      " [  37  216]]\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_out, y_pred_rf)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ebdb6684-db19-4f69-baf8-aabb513ec779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the Decision Tree model\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "decision_tree.fit(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89681e0d-4757-4c1d-9aa7-a0f9f0628707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_dt = decision_tree.predict(X_test_scaled)\n",
    "y_pred_probs_dt = decision_tree.predict_proba(X_test_scaled)[:, 1]  # probabilities for the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "789fd56f-117b-4e1f-9814-6d9d7bbcf88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Test Accuracy: 0.9649\n",
      "Decision Tree Test Precision: 0.8565\n",
      "Decision Tree Test Recall: 0.9497\n",
      "Decision Tree Test F1 Score: 0.9007\n",
      "Decision Tree Test ROC AUC: 0.9594\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "test_precision_dt = precision_score(y_test, y_pred_dt, zero_division=1)\n",
    "test_recall_dt = recall_score(y_test, y_pred_dt, zero_division=1)\n",
    "test_f1_dt = f1_score(y_test, y_pred_dt, zero_division=1)\n",
    "test_roc_auc_dt = roc_auc_score(y_test, y_pred_probs_dt)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Decision Tree Test Accuracy: {test_accuracy_dt:.4f}\")\n",
    "print(f\"Decision Tree Test Precision: {test_precision_dt:.4f}\")\n",
    "print(f\"Decision Tree Test Recall: {test_recall_dt:.4f}\")\n",
    "print(f\"Decision Tree Test F1 Score: {test_f1_dt:.4f}\")\n",
    "print(f\"Decision Tree Test ROC AUC: {test_roc_auc_dt:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b4036931-9df4-4bdc-a433-c4728c2525db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_dt = decision_tree.predict(X_out_scaled)\n",
    "y_pred_probs_dt = decision_tree.predict_proba(X_out_scaled)[:, 1]  # probabilities for the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "65ae975f-cbca-4cd6-b7f4-214916fbc95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Out-Sample Accuracy: 0.7768\n",
      "Decision Tree Out-Sample Precision: 0.3020\n",
      "Decision Tree Out-Sample Recall: 0.5850\n",
      "Decision Tree Out-Sample F1 Score: 0.3984\n",
      "Decision Tree Out-Sample ROC AUC: 0.6948\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "out_accuracy_dt = accuracy_score(y_out, y_pred_dt)\n",
    "out_precision_dt = precision_score(y_out, y_pred_dt, zero_division=1)\n",
    "out_recall_dt = recall_score(y_out, y_pred_dt, zero_division=1)\n",
    "out_f1_dt = f1_score(y_out, y_pred_dt, zero_division=1)\n",
    "out_roc_auc_dt = roc_auc_score(y_out, y_pred_probs_dt)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Decision Tree Out-Sample Accuracy: {out_accuracy_dt:.4f}\")\n",
    "print(f\"Decision Tree Out-Sample Precision: {out_precision_dt:.4f}\")\n",
    "print(f\"Decision Tree Out-Sample Recall: {out_recall_dt:.4f}\")\n",
    "print(f\"Decision Tree Out-Sample F1 Score: {out_f1_dt:.4f}\")\n",
    "print(f\"Decision Tree Out-Sample ROC AUC: {out_roc_auc_dt:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "17ce1e8d-80ab-4206-b7f7-11a4838991af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1408  342]\n",
      " [ 105  148]]\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the confusion matrix\n",
    "cm = confusion_matrix(y_out, y_pred_dt)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2d90e-b50e-48a8-b895-84bdaf69b38c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
